

## 这不是认认真真的笔记。

我接触编程到现在也2年了，学校开的水课组成原理，C++，数据结构与算法，操作系统也都上过了。

所以，这里不再是一种系统性的学习，而是希望在之前的程度上再深挖一点，比如学校课真的水（操作系统把linux的基本命令和系统管理过一遍就完了，其他都是考概念，一两天突击一下就过去了。）导致我自己虽然学过这些课，但我完全没有底气说自己真的懂这些。

我会找出我在意的地方记录，以及，记录是主观的。



## Day 1:

### Compile型和Interpret型的高级语言区别。

Compile型代表:C语言

main.c  : source code,遵循C语言语法的文本文件。

---- compiled  经过gcc的编译。

> **常见标准库在glibc中，并且glibc还提供一些linux的系统底层接口。**

->main.out: 可执行的文件，通常是可以被系统接受的机器码。

```bash
gcc main.c -o main.out
./main.out
```

Interpret型代表:Python

不同于C,有这样的语法结构:

```python
>>a=1
>>b=2
>>c=a+b
>>c
3
```

它有记忆性，可以逐行运行。

另外，它和操作系统似乎是有剥离的，是一种虚拟平台。

和C相比，C编译后是可以直接被操作系统接受的，是直接运行在操作系统内核的，不知道这么讲是不是准确。

而python通常需要一个python的解释器，它运行时是一种类似虚拟环境的东西。有一层软隔离吧，虽然说必然得是操作系统运行的，但我觉得因为python的pyrc也不是机器码，而是得由python解释器像上面那样逐行运行，因此我认为它和操作系统的无关性和隔离性要比C语言更好。

但这样会有的缺点就是一样的指令运行会更慢。比如循环打印，自增自减等等，应该也是由于虚拟化。

#### 高级语言的移植性：

C语言相对于汇编和机器语言算得上高级语言。

因为我记得汇编和机器语言一一对应。

而C语言不管mac上还是windows上还是linux上写的语法都一样，区别只在编译器，最后编译时翻译出来的机器码和调用的底层不同。所以在不同的机器之间移植不需要变动源代码而只需要更换编译器，这就很好的能被迁移到不同的系统平台。只要有人写编译器吧我觉得。

而Python那边，也类似，它用的解释器被miniconda给封装起来了，我虽然linux和windows都有用，但是没仔细观察python解释器是不是不同。

但至少这也很简单的说明了为什么linux和windows之间的环境不能直接copy。

首先python底层有C，C在两个系统之间编译必然是不同的。那么python环境也是不能移植的，有点牵强好像。

>###### 1.1 什么是 CPython？
>
>CPython 是 Python 语言的一个主要实现，它是用 C 语言编写的 Python 解释器。当你在大多数 Linux、Windows 或 macOS 上安装并运行 Python 时，你实际运行的就是 CPython。Python 代码在 CPython 中会被解析、编译成字节码（bytecode），然后由解释器逐行执行这些字节码。
>
>因此，Python 和 C 之间的直接关系就是：Python 的核心解释器 CPython 是由 C 语言实现的。
>
>###### 1.2 CPython 的工作流程
>
>- **解析器（Parser）**：CPython 将 Python 源代码解析为语法树（AST）。
>- **编译器（Compiler）**：将 AST 编译为 Python 字节码，这是一种中间形式，用于虚拟机解释执行。
>- **Python 虚拟机（PVM, Python Virtual Machine）**：解释并执行这些字节码。PVM 本身也是用 C 语言编写的。
>
>这意味着，当你编写并执行 Python 代码时，C 语言代码在后台负责解释和执行你编写的 Python 代码。

这么看起来，python是C的宝宝，从解释到运行全都在C的一个虚拟化环境下。这个虚拟化环境和系统应该是一个主机和docker关系。

区别主要在于，是否直接翻译成操作系统内核接受的机器码并且直接由操作系统内核来运行。



### printf和scanf:

因为学的时候是c++，printf用得少，scanf没见过。

C++咋写来着

```c++
std::cout<<"hello world";

std::cin<<"your age"<<age;
```

完全忘了cin这东西。

scanf和cin类似，也和python的input()差不多。

咱之后不写C++了，学好C就可以了。C++语法规则太他妈多了，而且类也不好写。要面向对象用python它不好吗？

> ps:C++ 里用的是iostream,C用的是stdio。



## Day2:



### C语言内存管理布局和变量，地址，指针存储分布：



示例：

```c
#include<stdio.h>

void cal(){
        int i;
        printf("%d\n",i);
        i = 777;
        printf("%d\n",i);
}

int main(){
        cal();
        cal();

        printf("=======================\n");
        cal();
        printf("Hello\n");
        cal();
        return 0;
}
```

```bash
root@DESKTOP-3I1GRP0:/home/xnne/Linux_C_Programing# ./main
0
777
777
777
=======================
22091
777
Hello
22091
777
```

第二次执行时，22091发生了变化

```cmd
root@DESKTOP-3I1GRP0:/home/xnne/Linux_C_Programing# ./main
0
777
777
777
=======================
22073
777
Hello
22073
777
```



关注点在于i的未初始化值的打印，

四次分别是:

```cmd
0
777
22091
22091
```

0的那次，是函数初始化。

777，是第一次初始化777后。

22091/22073,是执行了printf后，虽然printf的内容不一样。【**以及，为什么两次不一样**】

对于**未初始化的全局变量和静态变量**，会被统一初始化为0。

![Snipaste_2024-09-06_09-01-32](https://fastly.jsdelivr.net/gh/MrXnneHang/blog_img/BlogHosting/img/24/09/202409060903980.jpeg)

这样不会导致值溢出，因为静态变量和全局变量的数据类型一开始就定义好，包括数组也会有固定长度。所以全部为0之后修改也不会溢出。

而我们的i作为局部变量，它的0不是全局统一初始化的，而是掐好分配到地址上面的变量就是0，可能是栈在程序启动的时候也做了一次类似格式化的操作，把地址上的值都格成0了。

#### 局部变量的位置：栈上，执行时分配，结束时释放。几十MB。

#### 函数指针（地址）的位置：栈上，包含返回地址（该示例中主函数地址）

栈的起始点是高地址，先进后出。

非常符合嵌套函数执行。

比如a -> b -> c -> d。

但是在返回时是依次返回的，是d->c->b->a

比如说简单写一个:

```python
i = 10
def a():
   i+=1
   b()
   print(i)
def b():
    i+=1
    c()
    print(i)
def c():
    i+=1
    d()
    print(i)
def d():
    i+=1
    print(i)
```

这一定是个垃圾程序，我都懒得想这到底打印出来会是什么样的。

但是你可以发现，print(i)的顺序是,d->c->b->a.

也就是说，每次我一次次进入函数，但是退出也是一个个退出的。

先进，后出，a最先进来，但是是最后出来的。

函数指针地址放在栈上是非常合适的。



##### 我们可以解释为什么两次"./main"执行时打印出的垃圾值都不一样

22091/22073,虽然很接近。

连续执行都差不多在21800~22200之间。

这个可能是主函数的地址，或者执行函数的地址。

我个人偏向于主函数地址。

因为两个垃圾值是一样的，而两次printf的地址必然是不一样的，所以，这个很大概率是main函数的地址的一部分。告知printf的返回是main地址。



#### 动态内存和堆空间：

new,malloc,realloc可以分配堆内存，是随时可以更改的，只要剩余空间充足，那都可以作为堆空间。

#### 代码段和数据段：

data segment:全局变量，静态变量位置。也有一个特殊区块是未初始化的数据段。

text segment:指令存放位置。之前提到，函数的地址在栈上，而text segment是指令，也就是函数的执行内容。而且指令应该有冗余，统一放一起可以节省空间。

都是预分配固定大小的，应该在编译的时候就计算好了。或者说在程序执行的时候就计算好了。

按理来说，机器指令不应该有内存管理意识，所以应该还是归功于C语言的编译器。



#### 程序指针pc:

不在内存里，在处理器里，应该和那个高速缓存有关，英文名称我忘了。



#### 内存布局图。

![Snipaste_2024-09-06_08-53-00](https://fastly.jsdelivr.net/gh/MrXnneHang/blog_img/BlogHosting/img/24/09/202409060933802.jpeg)

segment预分配，固定大小，程序运行中一般不变。

Stack固定大小，反复初始化释放。

Heap，除非free或者delete，否则一直存在，并且可以一直动态扩展，直到顶到了Stack。

#### 哲学问题:

##### 哲学问题a:但通常会有大聪明在函数里面放一个int a[30000],这不爆炸吗？这个应该怎么处理。

会爆炸，考虑转全局，或者动态分配到栈，只在函数域里留下一个指针。

##### 哲学问题b：如果全局声明指针然后用动态分配内存那么它应该在哪里？

指针存在data segement里，这依然不会改变大小。

而后续分配在堆内存里。



不仅感叹天才，非常简单的设计，但是非常的高效率。