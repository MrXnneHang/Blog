2024.4.13

# 玻璃缺陷检测实现

本项目采用yolov8模型

yolo目标检测与分类的过程：

1.  **图像预处理**：输入图像首先被缩放到YOLOv8模型指定的尺寸。通常，这涉及到调整图像大小和归一化处理。

2.  **特征提取**：YOLOv8使用一种称为CSP（Cross Stage Partial）的Darknet架构来提取图像特征。这个架构包含多个卷积层和残差连接，能够有效地提取图像中的特征。

3.  **分割图像为网格**：与之前的YOLO版本一样，输入图像被分割成一个网格。每个单元格负责检测其区域内的对象。

4.  **边界框预测**：对于每个单元格，YOLOv8预测一个或多个边界框。这些边界框的预测包括边界框的位置（中心坐标、宽度和高度）和边界框的置信度。置信度是对象存在概率和边界框准确度的乘积。

5.  **类别预测**：每个单元格还预测边界框内对象属于各个类别的概率。这些类别概率与边界框的置信度相结合，以计算每个边界框的最终置信度。

6.  **非极大值抑制（NMS）**：由于多个单元格可能会预测出重叠的边界框，因此需要使用非极大值抑制来合并这些重叠的预测。NMS的过程是：

    *   根据置信度对所有预测框进行排序。

    *   选择置信度最高的框作为输出。

    *   删除所有与所选框有高重叠度的框。

    *   重复上述过程，直到所有框都被考虑过。

7.  **输出最终结果**：经过NMS处理后，每个检测到的对象都会有一个边界框和相应的类别标签。这些结果就是YOLOv8模型的最终输出。 YOLOv8在实现这些基本步骤的同时，引入了一些新的特性和改进，如更高效的架构、改进的锚点（anchor）机制、更快的训练和推理速度等，以提高目标检测的准确性和效率。

## 一.环境与依赖的创建

​	**1.打开conda，创建虚拟环境：**

```cmd
conda create --name glass python=10.1（python版本的选择要根据依赖支持的版本进行选择）
```

​	**2.下载pytorch框架：**

进入pytorch官网，复制命令：

```cmd
pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
```

​	**3.下载依赖：**

*   ultralytics

*   roboflow（下载时要求opencv库版本大于4.6.0）

*   opencv

## 二.数据集的获取：

​	1.打开roboflow官网，进入工作区，点击新建项目：

​	2.填写项目信息

​	3.上传图片

​	4.数据处理

​	5.下载数据集：（格式为yolov8） ​&#x9;

​	复制代码，将下载代码放入自己的项目中，用于下载数据集

​	5.修改数据集路径：

*   在下载的数据集文件夹中找到data.yaml文件

*   复制修改test，train，value的路径：（复制后要修改：反斜杠，根目录/，不要c，d盘）

    ![1712974149039](https://fastly.jsdelivr.net/gh/MrXnneHang/blog_img/BlogHosting/img/24/06/202406201033995.png)

    ### 问题

## 三.训练

1.  确定参数：（参考这篇文章）

​	[YOLOv8训练参数详解（全面详细、重点突出、大白话阐述小白也能看懂）-CSDN博客](https://blog.csdn.net/qq_37553692/article/details/130898732)

1.  输入命令：

```cmd
yolo task=detect mode=train model=/code/git/glass-detect/yolov8n.pt data=/code/git/glass-detect/Hard-Hat-Sample-2/data.yaml epochs=20 workers=0 imgsz=640
```

1.  观察训练结果：

    在run文件夹下找到result.csv与result.png分析训练结果是否符合预期

    ![1712977387650](https://fastly.jsdelivr.net/gh/MrXnneHang/blog_img/BlogHosting/img/24/06/202406201033332.png)

2.  获取权重文件： 在run文件夹中点击weights：

    ![1712977526494](https://fastly.jsdelivr.net/gh/MrXnneHang/blog_img/BlogHosting/img/24/06/202406201035597.png)

### **问题**

​	1.在确定参数时，如果训练是在本地运行且为windows系统，一定要将works参数改为0，不然默认多线程会把内存占满）

​	2.模型参数以及数据集位置注意：反斜杠，根目录/，不要c，d盘。参考图示命令

​	3.在运行代码时输出的结果太长，无法全部显示 	解决： 	![1712979078135](https://fastly.jsdelivr.net/gh/MrXnneHang/blog_img/BlogHosting/img/24/06/202406201034000.png) 	\*找到设置

 ![1712979189574](https://fastly.jsdelivr.net/gh/MrXnneHang/blog_img/BlogHosting/img/24/06/202406201034860.png)

## 四.验证

​	输入命令：

`!yolo task=detect mode=val model=/code/git/glass-detect/runs/detect/train/weights/best.pt data=/code/git/glass-detect/Hard-Hat-Sample-2/data.yaml`

## 五.导出模型

将训练好的权重于架构导出为onnx或tflite模型

1.使用yolo命令行导出onnx架构:

```python
! yolo task=detect mode=export model=./weight/best.pt format=onnx
```

2.使用aidlux平台的转化模型平台：[AI Model Optimizer (aidlux.com)](https://aimo.aidlux.com/#/detail/c7cc1b98-5991-42ff-826a-f4a9193ca2ac)将onnx转化为tflite模型

## 六.模型部署aidlux

具体：[平台介绍 (aidlux.com)](https://docs.aidlux.com/#/)

### 手机上aidlux平台杀进程问题：

[鸿蒙/HarmonyOS 3.0 后台运行AidLux- AidLux开发者社区](https://community.aidlux.com/postDetail/827)

[AidLux在Android12+/鸿蒙3+服务进程被杀解决方案- AidLux开发者社区](https://community.aidlux.com/postDetail/593)

[ADB 使用教程- AidLux开发者社区](https://community.aidlux.com/postDetail/821)

原因：android12对虚拟线程的限制导致多进程的应用会被强制关闭

解决：

1.电脑端下载adb（安卓电脑连接桥）并配置环境变量

![](https://fastly.jsdelivr.net/gh/MrXnneHang/blog_img/BlogHosting/img/24/06/202406201034134.jpeg)

2.进入手机端，进入开发者模式，打开调试模式

3.进入cmd输入：

查看设备是否连接成功：

`adb shell devices`

将最大进程数量改为2147483647：

`adb shell "/system/bin/device_config put activity_manager max_phantom_processes 2147483647"`

将最大虚拟进程改为32

`adb shell "/system/bin/device_config put activity_manager max_phantom_processes 32"`

### aidlux所有的环境配置：

#### 1.远程连接aidlux

#### 2.远程连接vscode：

[Aidlux\&VScode编程调试及AI案例测试\_aidlux安装vscode-CSDN博客](https://blog.csdn.net/m0_54361461/article/details/127595442) 每次ip地址需要更改

#### 3.安装python虚拟环境：&#x20;

进入home目录&#x20;

&#x20;   1.安装python3-venv包

    sudo apt-get install python3-venv

​	2.安装虚拟环境（在当前目录）

    python3 -m venv myenv

​	3.激活虚拟环境（在当前目录）

    source myenv/bin/activate

​	4.pip更换清华源：

    pip config set global.index-url https://pypi.tuna.tsinghua.edu.cn/simple

​	5.安装需要的依赖

​	6.在虚拟环境中新建文件夹放全部代码

​	**注意：** ​	远程连接时要先进入aidlux主环境再激活虚拟环境

#### 4.运行py文件：

cd到文件目录，运行文件：

    python3 文件.py

注意：在aidlux中打开摄像头要用cvs库：

    import cv2
    from cvs import *
    cap = cvs.VideoCapture(0)  # 0代表默认摄像头
    frame = cap.read()
    cvs.imshow(frame)

对于摄像头有关代码都需要修改

#### 5.为aidlux换debain源：

原因：安装jupyter和ultralytics时报错：在安装`psutil`库时遇到了问题。

这通常是因为缺少编译扩展所需的工具。错误消息提示缺少`gcc,`这是编译C语言代码的常用工具。另外，它 还提到了缺少Python开发头文件，这些头文件通常包含在`python3-dev`包中。

因此安装`psutil`库则需要安装gcc以及`python3-dev`包

而安装gcc库与python3-dev包需要使用linux的下载工具debain源

测试发现debain源中的华为云源出错，需要更换

解决：

&#x20;   1.输入`vi /etc/apt/sources.list`在vi编辑器中打开源列表：

&#x20;   2.输入i（insert）命令进入编辑模式将华为云源全部删除，更换为清华源

&#x20;   3.按esc键退出编辑模式，输入（：wq）退出并保存

&#x20;   4.更换完毕，可以正常使用

&#x20;   5.输入`sudo apt-get install gcc python3-dev`

&#x20;   6.安装完后输入`pip install psutil`或直接安装`jupyter`

### 部署模型：

[工业视觉少样本缺陷检测实战应用：AidLux平台的创新实践-腾讯云开发者社区-腾讯云 (tencent.com)](https://cloud.tencent.com/developer/article/2369084)

[python - 使用YOLOv8进行工业视觉缺陷检测，基于Aidlux完成本地终端部署 - 个人文章 - SegmentFault 思否](https://segmentfault.com/a/1190000044204898)

[AidLux—极简的开发和部署体验 - Goafan - 博客园 (cnblogs.com)](https://www.cnblogs.com/goafan/p/16833503.html)

[基于AidLux+Yolov8，实现安卓手机检测纺织物瑕疵\_yolov8 android-CSDN博客](https://blog.csdn.net/GONG4717/article/details/130977216)

在aidlux上我们将运行完整的程序，包括：模型加载，输入数据的预处理，推理，输出数据的后处理，通过输出结果进行的操作

#### 导入相应的库：

注意：aidlite\_gpu库在opencv-contrib-python中

#### 1.模型加载：

通用的模型加载公式：

```python
inShape:list = [1*3*640*640*4]   #定义输入数据的大小，因为使用的是float32的数据格式，所以后面要*4
outShape:list = [1*7*8400*4]
model_path = "./best.tflite" #在aidlux平台的jupyter中运行时路径可以为相对路径，若是直接调用python解释器则不能用相对路径要用绝对路径
aidlite = aidlite_gpu.aidlite() 
#二选一
# detect = aidlite.ANNModel(model_path,inShape,outShape,3,-1) #加载模型，输入（模型路径，输入与输出大小，所选的核数，推理的设备id）
detect = aidlite.FAST_ANNModel(model_path,inShape,outShape,3,-1)

```

特用的模型加载：

#### 2.输入数据的预处理：

基本的预处理公式：

```python
    input:np.array = cv2.resize(image,dsize=[640,640],interpolation=cv2.INTER_LINEAR) #使用OpenCV（cv2）读取的图片本身就是NumPy数组
    input = input/255.0    #将像素值控制在0-1中，归一化
    input = np.expand_dims(input,0)    #给输入数据增加一个维度
```

#### 3.推理

推理通用公式：

```python
    detect.invoke()    
   outputs = aidlite.getOutput_Float32(0)    #输出的是一维向量，与正常模型输出形状不一样
```

#### 4.输出数据的后处理

通用的处理公式：

```python
outputs:np.array = outputs.reshape(1,8400,7)   #将输出改编为模型正常输出的形状
```

还要对输出的数据进行信息提取，具体模型具体分析

yolo模型：

&#x20;   输出8400(或更多)个单元格，每一个单元格都有对应的7(或更多)个预测值，依次为（x，y，w，h，分类）

#### 5.通过输出结果进行的操作

对提取完信息的模型，根据模型输出的预测结果，我们可以通过各种需要的方式对结果进行操作，具体项目具体分析

玻璃检测项目：\
对于多个预测值，若多次有检测到缺陷，就将标志位置1，若没有检测到，就将标志位置0，标志位的状态位记录标志位的前一个状态。

当标志位为1，状态位为0，表示玻璃刚刚进入检测区域，并且检测到缺陷。

当标志位为0，状态位为1，表示玻璃刚刚走出检测区域，并且是有缺陷的

若标志位与状态位一直为0，表示玻璃是完好的
